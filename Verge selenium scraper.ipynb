{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "terminal-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import json\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "\n",
    "#from webdriver_manager.chrome import ChromeDriverManager \n",
    "#driver=webdriver.Chrome(ChromeDriverManager().install()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "proper-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Verge_scraper:\n",
    "    \n",
    "    def __init__(self,year,month):\n",
    "        self.year = year\n",
    "        self.month = month\n",
    "        self.base_url = \"https://www.theverge.com/archives\" \n",
    "    def _url(self):    \n",
    "        url =  self.base_url+\"/\"+self.year+\"/\"+self.month\n",
    "        return url\n",
    "    \n",
    "    def open_url(self):\n",
    "        driver = webdriver.Chrome(CHROME_PATH)\n",
    "        driver.get(self._url())\n",
    "        driver.maximize_window()\n",
    "        done = True\n",
    "        \n",
    "        while done:\n",
    "            try:\n",
    "                wait = WebDriverWait(driver,10)\n",
    "                self.scrolling_func(wait)   \n",
    "                driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + Keys.HOME)\n",
    "            except:\n",
    "                done=False\n",
    "\n",
    "        headlines = []\n",
    "        dates = []\n",
    "        \n",
    "        #https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "        soup = BeautifulSoup(driver.page_source,'lxml')\n",
    "        for title in soup.find_all(\"h2\",class_=\"c-entry-box--compact__title\"):\n",
    "            headlines.append(title.text)\n",
    "        for date in soup.find_all(\"time\",class_=\"c-byline__item\"):\n",
    "            dates.append(date.text.strip())\n",
    "        \n",
    "        assert len(headlines)==len(dates), \"Different lengths of headlines and date\"\n",
    "        data = {\"Headlines\":headlines,\"Dates\":dates}\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    \n",
    "    def scrolling_func(self,wait):\n",
    "        SCROLL_PAUSE_TIME = 1.0\n",
    "\n",
    "        # Get scroll height\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        while True:\n",
    "            # Scroll down to bottom\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "            # Wait to load page\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "            element = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '.p-button')))\n",
    "            load_button = driver.find_element_by_css_selector('.p-button')\n",
    "            load_button.click()\n",
    "            # Calculate new scroll height and compare with last scroll height\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "incorporated-cooling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30\n"
     ]
    }
   ],
   "source": [
    "CHROME_PATH = r\"C:\\Users\\astar\\Stock market tutorials\\chromedriver_win32\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(CHROME_PATH)\n",
    "driver.maximize_window()\n",
    "\n",
    "driver.get(\"https://www.theverge.com/archives/2021/3\")\n",
    "clicks = 0\n",
    "\n",
    "done=True\n",
    "\n",
    "while done:\n",
    "    try:\n",
    "        wait = WebDriverWait(driver,10)\n",
    "        scrolling_func(wait)   \n",
    "        driver.find_element_by_tag_name('body').send_keys(Keys.CONTROL + Keys.HOME)\n",
    "    except:\n",
    "        done=False\n",
    "\n",
    "headlines = []\n",
    "dates = []\n",
    "links = []\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source,'lxml')\n",
    "#https://stackoverflow.com/questions/5041008/how-to-find-elements-by-class\n",
    "for title in soup.find_all(\"h2\",class_=\"c-entry-box--compact__title\"):\n",
    "    headlines.append(title.text)\n",
    "#     links.append(title.href)\n",
    "for date in soup.find_all(\"time\",class_=\"c-byline__item\"):\n",
    "    dates.append(date.text.strip())\n",
    "\n",
    "print(len(headlines),len(dates))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-smooth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
